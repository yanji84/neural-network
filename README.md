Implementation of modularly designed convolutional/fully connected neural network. The nn layers include recent advancement in nn training techniques including dropout regularization and batch normalization. Various update rules (sgd with momentum, rmsprop, and adam) are also included to compare with the performance of vanila stochastic gradient descent.

Homework solution to Stanford NN class
